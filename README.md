# Проектная работа 4 спринта

## Задание 1. Выбор и реализация решения для пакетной обработки данных

Маркетинговый отдел планирует расширенно обрабатывать данные клиентов, объединяя их из разных источников, и формировать отчёты. В работе используются данные из разных источников: файловое хранилище CSV-файлов, содержащих статусы доставок пользователей, таблицы PostgreSQL с информацией о заказах, данные о платежах по заказам, расширенные данные о пользователях и данные из Kafka с цепочкой событий по модификации заказов.

Текущая система обработки не справляется с нагрузкой и запрашиваемым функционалом. Поэтому необходим выбрать и обосновать технологическое решение для пакетной обработки данных.
Логика обработки подразумевает возможность гибко формировать пайплайна, интегрировать его с внешними API, BigQuery, Redshift, Kafka и Spark, а также поддерживать встроенный мониторинг и оповещения. Ожидаемый объём обрабатываемых данных за один запуск пайплайна — около 1 млн. 
Продемонстрируйте локально развёрнутое решение, которое впоследствии компания сможет применить в облачной инфраструктуре.

### Что нужно сделать

1. Обосновать выбор технологического решения
    - Опишите, как выбранное решение можно интегрироваться с BigQuery, Redshift, Kafka и Spark, отметив, есть ли для него готовые модули, которые ускорят разработку.
    - Решение поддерживает возможность ветвления, условных операторов и event-triggers?
    - Можно ли использования из коробки fallback-logic, retry и отправку email-уведомлений?
    - Обоснуйте, как решение будет развернуто в облачной среде.
2. Продемонстрировать POC (Proof of Concept) на примере простого проекта

    Запишите скринкаст или сделайте скриншоты. Должно быть видно локально развёрнутое решение и простой пайплайн, который содержит следующие шаги:
    - Чтение из источника данных (база данных, файловая система).
    - Анализ данных и ветвление пайплайна при выполнении условия.
    - Настройка email-уведомления при успешном и неуспешном завершении пайплайна.
    - Настройка retry-политики для шагов пайплайна.

    В результате у вас должно получиться обоснование выбранного решения, файл (или файлы) с кодом/конфигурацией пайплайна и демонстрация его в локальном развёртывании в виде скринкаста или скриншотов.

## Задание 2. Разработка дизайна модуля пакетной обработки данных

Каждое утро ровно в шесть онлайн-магазину нужно сгенерировать кастомные CSV/XLS прайс-листы для B2B-клиентов на основе текущих данных в БД. Процесс выгрузки не требует дополнительной логики по обработке данных.

Данные в PostgreSQL представлены в таблицах:

- products ~ 5 000–10 000 строк;
- categories ~ 50–200 строк;
- clients ~ 100–500 строк;
- client_prices ~ 10 000–20 000 строк.

Необходимо связать данные из таблиц и выгрузить их в CSV-файл. Объём данных 5 000 –10 000 строк. Инфраструктура магазина — микросервисы в облаке.

### Что нужно сделать

1. Обоснуйте выбор технологического решения. Вы можете воспользоваться шаблоном, на основе которого раскрыть собственные мысли, почему вы остановились именно на таком решении.

| | SpringBatch | ApacheAirflow | K8s Job | Spark |
| --- | --- | --- | --- | --- |
| Наличие конфигурации CRON-расписания | | | | |
| Сложность реализации логики по обработке данных | | | | |
| Ресурсоемкость решения (количество потребляемых ресурсов) | | | | |
| Масштабируемость решения под нагрузкой и сложность реализации | | | | |
| Сложность развертывания в облаке и интеграция с имеющейся микросервисной  архитектурой | | | | |
| Удобство интеграции с системами логирования и мониторинга  | | | | |

2. Составьте диаграмму контекста C4-архитектуры системы To Be. Опишите, как будет работать решение.

3. Подготовить верхнеуровневый пошаговый план конфигурации и его имплементации, который выполняют требуемый функционал.

В результате у вас должен получиться файл с заполненной таблицей и выводами, обосновывающими выбор решения, С4-диаграмма To Be, а также документ с наброском верхнеуровневого плана по имплементации и конфигурации решения.

## Задание 3. Реализация Distributed Scheduling с k8s CronJob

Онлайн-платформа занимается грузоперевозками. Каждый день ровно в восемь вечера ей нужно выгружать данные в специализированное хранилище для аналитиков. На основе выгруженных данных обновляются дашборды дневной отчётности. В связи с текущим стеком и опытом разработчиков остановили на k8s CronJob.

Ежедневный объём данных включает следующие таблицы:

- shipments (перевозки) ~ 50 000–200 000 строк;
- shipment_events (события по перевозкам) ~ 500 000–1 000 000 строк;
- drivers (водители) ~ 1 000–5 000 строк;
- vehicles (транспорт) ~ 500–2 000 строк;
- clients (заказчики) ~ 10 000–50 000 строк.

### Что нужно сделать

Подготовьте yaml-файлы конфигурации, которые выполняют требуемый функционал. Достаточно реализовать метод простого экспорта данных одной таблицы из БД на удобном вам языке программирования.

В результате у вас должны получиться конфигурационные файлы для создания Docker-образа, конфигурационные файлы k8s job, чтобы использовать Docker-образа с cron-конфигурацией, а также видео или скриншоты, которые продемонстрируют работу k8s job в MiniKube.

Загрузите всё в директорию Task3 вашего репозитория.
